% ============================================================
% INTRODUCTION SECTION
% ============================================================

\section{Introduction}\label{sec:intro}

Sepsis remains one of the most pressing challenges in critical care, responsible for nearly twenty percent of global mortality and more than \$62 billion in annual U.S.\ healthcare expenditures \citep{rudd2020sepsis, fleischmann2016sepsis}. Despite successive iterations of the Sepsis-3 definition \citep{singer2016sepsis3} and aggressive early-intervention campaigns, outcomes have plateaued: mortality still ranges from 10--20\% for sepsis without shock to 40--50\% for septic shock. Clinicians must synthesize heterogeneous physiological signals and act within hours, yet existing protocols offer only population-level heuristics for fluid resuscitation, vasopressor titration, and escalation to organ support \citep{rhodes2017ssc}. Large randomized trials that re-evaluated early goal-directed therapy (EGDT) \citep{rivers2001egdt, arise2014} underscore the difficulty of prescribing universally optimal intervention thresholds.

Reinforcement learning (RL) has emerged as a candidate framework for tailoring sepsis therapy to patient trajectories. By optimizing long-horizon rewards, RL-based policies can, in principle, balance competing short-term hemodynamic targets against downstream survival. Early work trained Deep Q-Network (DQN) and fitted Q-iteration policies on MIMIC-III data, showing promising retrospective survival estimates \citep{raghu2017sepsis_drl, komorowski2018ai_clinician}. However, these studies emphasized expected returns and policy deviations from clinician behavior while offering only qualitative or aggregate descriptions of why certain actions were recommended. As sepsis RL research shifts toward the offline setting—where algorithms must learn exclusively from historical data—questions about policy interpretability become central. Offline methods ranging from Behavior Cloning (BC) to Conservative Q-Learning (CQL) and offline-adapted DQN handle uncertainty and distribution shift differently, which plausibly shapes the transparency of their learned decision rules.

A rigorous understanding of how offline RL algorithms trade off performance and interpretability is still missing. Existing evaluations lack quantitative feature-attribution analyses—a gap with direct regulatory consequences. The U.S.\ Food and Drug Administration requires explainable AI systems for medical decision support \citep{fda2021ai}, yet no sepsis RL study has demonstrated whether high-performing policies expose clinically plausible decision rationales that clinicians can validate and trust \citep{holzinger2017xai_healthcare}. Moreover, interpretability techniques for sequential decision-making—such as Linearly Estimated Gradients (LEG) saliency maps \citep{greydanus2018leg}—have rarely been applied to healthcare RL, so it remains unclear which algorithmic choices yield explanations aligned with accepted sepsis physiology.

Responding to this gap, we ask: \textit{Can offline RL algorithms for sepsis simultaneously deliver state-of-the-art survival performance and clinically interpretable decision rationales?} We hypothesize that performance--interpretability trade-offs depend on algorithmic design and that conservatism in the objective (as in CQL) can enhance both safety and transparency. To test this hypothesis, we train BC, CQL, and DQN policies on a dataset of simulated patient trajectories generated by rolling out a heuristic policy in the gym-sepsis simulator—an environment whose dynamics and outcome models were trained on MIMIC-III data \citep{raghu2017sepsis_drl}. We jointly evaluate survival outcomes stratified by Sequential Organ Failure Assessment (SOFA) scores and LEG-based feature saliency, ensuring that both performance and interpretability are quantified rigorously.

This study contributes (i) the first quantitative benchmark of offline RL algorithms on both outcome metrics and interpretability for sepsis management, (ii) empirical evidence that the presumed performance--interpretability tension is not inevitable, with CQL matching the survival of alternative policies while providing salient, guideline-consistent explanations, and (iii) methodological guidance on applying LEG analysis to safety-critical RL deployments. Section~\ref{sec:related} surveys clinical RL and interpretability research, Section~\ref{sec:problem} formalizes the sepsis decision process and LEG framework, Section~\ref{sec:methods} details experimental design, Section~\ref{sec:results} reports performance and interpretability findings, Section~\ref{sec:discussion} interprets the implications for clinical adoption, and Section~\ref{sec:conclusion} outlines future research directions.

% End of Introduction section
